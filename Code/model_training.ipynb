{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\capstone\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU setup complete.\n"
     ]
    }
   ],
   "source": [
    "def setup_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"âœ… GPU setup complete.\")\n",
    "setup_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess .mp4 videos\n",
    "def load_video(video_path, max_frames=30, target_size=(224, 224)):\n",
    "    cap = cv2.VideoCapture(video_path.numpy().decode(\"utf-8\"))\n",
    "    frames = []\n",
    "    \n",
    "    for _ in range(max_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)  # Resize for MoViNet\n",
    "        frame = frame / 255.0  # Normalize pixels\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Pad if fewer than max_frames\n",
    "    while len(frames) < max_frames:\n",
    "        frames.append(np.zeros(target_size + (3,)))\n",
    "\n",
    "    return np.array(frames, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow dataset\n",
    "def create_dataset(directory, batch_size=8):\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for label, event in enumerate(sorted(os.listdir(directory))):\n",
    "        event_path = os.path.join(directory, event)\n",
    "        if os.path.isdir(event_path):\n",
    "            for file in os.listdir(event_path):\n",
    "                if file.endswith(\".mp4\"):\n",
    "                    video_paths.append(os.path.join(event_path, file))\n",
    "                    labels.append(label)  \n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((video_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: (tf.py_function(load_video, [x], tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset, labels\n",
    "\n",
    "# Load dataset directories\n",
    "train_data, train_labels = create_dataset(\"split_data/train\", batch_size=8)\n",
    "val_data, val_labels = create_dataset(\"split_data/eval\", batch_size=8)\n",
    "test_data, test_labels = create_dataset(\"split_data/test\", batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights (handling rare event detection)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(f\"Class Weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MoViNet-A3 from TensorFlow Hub\n",
    "model_id = 'a3'\n",
    "mode = 'stream'\n",
    "version = '3'\n",
    "model_url = f\"https://tfhub.dev/tensorflow/movinet/{model_id}/{mode}/kinetics-600/classification/{version}\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(model_url, trainable=True),\n",
    "    keras.layers.GlobalAveragePooling3D(),\n",
    "    keras.layers.BatchNormalization(),  \n",
    "    keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),  \n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(class_weights), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model with weighted loss\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with class weights\n",
    "epochs = 10  \n",
    "history = model.fit(train_data, validation_data=val_data, epochs=epochs, class_weight=class_weights_dict)\n",
    "\n",
    "# Save trained model (architecture + optimizer state)\n",
    "model.save(\"movinet_model.h5\")\n",
    "model.save(\"movinet_saved_model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"ðŸŽ¯ Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

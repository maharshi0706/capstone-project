{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11467197,"sourceType":"datasetVersion","datasetId":7186088},{"sourceId":11468620,"sourceType":"datasetVersion","datasetId":7186987},{"sourceId":344949,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":288351,"modelId":309127},{"sourceId":344950,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":288352,"modelId":309128}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U -q \"tf-models-official\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:37:52.612969Z","iopub.execute_input":"2025-04-19T03:37:52.613278Z","iopub.status.idle":"2025-04-19T03:37:56.397989Z","shell.execute_reply.started":"2025-04-19T03:37:52.613254Z","shell.execute_reply":"2025-04-19T03:37:56.397186Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\nimport moviepy.editor as mp\nfrom collections import defaultdict\nfrom official.projects.movinet.modeling import movinet, movinet_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:37:58.096436Z","iopub.execute_input":"2025-04-19T03:37:58.097139Z","iopub.status.idle":"2025-04-19T03:38:03.497445Z","shell.execute_reply.started":"2025-04-19T03:37:58.097107Z","shell.execute_reply":"2025-04-19T03:38:03.496882Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 03:37:58.501848: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745033878.524717     109 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745033878.531545     109 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1745033878.550014     109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745033878.550038     109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745033878.550040     109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745033878.550043     109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def preprocess_video(video_path, num_frames=16, resolution=224):\n    print(f\"Attempting to open video: {video_path}\")  \n    cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG, params=[])\n    if not cap.isOpened():\n        raise ValueError(f\"Could not open video file: {video_path}. Ensure FFmpeg is installed and file is valid.\")\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_step = max(1, total_frames // num_frames)\n    \n    for i in range(0, total_frames, frame_step):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, (resolution, resolution))\n        frame = frame / 255.0  \n        frames.append(frame)\n    \n    cap.release()\n    while len(frames) < num_frames:\n        frames.append(np.zeros((resolution, resolution, 3)))\n    return np.array(frames[:num_frames])\n\ndef predict_events(model, video_data, class_names, threshold=0.5):\n    event_timestamps = []\n    print(f\"Predicting events from preprocessed data with shape: {video_data.shape}\")\n    video_data = np.expand_dims(video_data, axis=0)\n    predictions = model.predict(video_data, verbose=0)\n    print(f\"Raw predictions: {predictions}\")\n    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS) if 'video_path' in globals() else 30.0  \n    total_frames = video_data.shape[0] * (max(1, int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT)) // video_data.shape[1]))\n    for i in range(0, total_frames, max(1, total_frames // video_data.shape[1])):\n        pred = predictions[0]\n        for idx, confidence in enumerate(pred):\n            if confidence > threshold:\n                timestamp = (i / fps) if i < total_frames else (total_frames / fps) / 2  \n                event_timestamps.append((timestamp, class_names[idx], confidence))\n    return event_timestamps\n\ndef preprocess_video_segment(frame, num_frames, resolution):\n    frames = [frame]\n    while len(frames) < num_frames:\n        frames.append(np.zeros((resolution, resolution, 3)))\n    return np.array(frames[:num_frames]) / 255.0\n\ndef create_highlight_reel(video_path, event_timestamps, output_path=\"/kaggle/working/highlight_reel_2.mp4\", window=5):\n    if not event_timestamps:\n        raise ValueError(\"No events detected to create a highlight reel.\")\n    clip = mp.VideoFileClip(video_path)\n    print(f\"Video duration: {clip.duration} seconds\")\n    print(f\"Creating highlight reel with {len(event_timestamps)} events: {event_timestamps}\")  \n    \n    timestamp_groups = defaultdict(list)\n    for timestamp, event, confidence in event_timestamps:\n        timestamp_groups[timestamp].append((event, confidence))\n    \n    clips = []\n    for timestamp, events in timestamp_groups.items():\n        try:\n            start_time = max(0, timestamp - window)\n            end_time = min(clip.duration, timestamp + window)\n            if start_time >= end_time:\n                print(f\"Skipping invalid timestamp {timestamp:.2f}s: start_time ({start_time:.2f}s) >= end_time ({end_time:.2f}s)\")\n                continue\n            event_clip = clip.subclip(start_time, end_time)\n            if event_clip is None or event_clip.duration <= 0:\n                print(f\"Invalid clip at {timestamp:.2f}s: duration {event_clip.duration if event_clip else 'None'}\")\n                continue\n            clips.append(event_clip)\n            print(f\"Added clip from {start_time:.2f}s to {end_time:.2f}s, duration {event_clip.duration:.2f}s for events {events}\")\n        except Exception as e:\n            print(f\"Failed to add clip at timestamp {timestamp:.2f}s: {e}\")\n    \n    if not clips:\n        raise ValueError(\"No valid clips were created for the highlight reel.\")\n    final_clip = mp.concatenate_videoclips(clips)\n    final_clip.write_videofile(output_path, codec=\"libx264\")\n    return output_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:38:05.925424Z","iopub.execute_input":"2025-04-19T03:38:05.926025Z","iopub.status.idle":"2025-04-19T03:38:05.938795Z","shell.execute_reply.started":"2025-04-19T03:38:05.925996Z","shell.execute_reply":"2025-04-19T03:38:05.938169Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def test_model(weights_path, video_path, class_names):\n    \n    batch_size = 1\n    num_frames = 16\n    resolution = 224\n    backbone = movinet.Movinet(model_id='a3')\n    backbone.build([batch_size, num_frames, resolution, resolution, 3])\n    model = movinet_model.MovinetClassifier(\n        backbone=backbone,\n        num_classes=len(class_names),\n        dropout_rate=0.7\n    )\n    model.build([batch_size, num_frames, resolution, resolution, 3])\n    model.load_weights(weights_path)\n    \n    \n    video_data = preprocess_video(video_path, num_frames, resolution)\n    event_timestamps = predict_events(model, video_data, class_names)\n    \n    \n    if event_timestamps:\n        print(\"Detected events:\")\n        for timestamp, event, confidence in event_timestamps:\n            print(f\"Event: {event}, Timestamp: {timestamp:.2f}s, Confidence: {confidence:.4f}\")\n    else:\n        print(\"No events detected with sufficient confidence.\")\n    \n    if event_timestamps:\n        output_path = create_highlight_reel(video_path, event_timestamps)\n        with zipfile.ZipFile(\"/kaggle/working/output_reel.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n            zipf.write(output_path, os.path.basename(output_path))\n        print(f\"Highlight reel generated: {output_path}. Download 'output.zip' from the Output tab.\")\n    else:\n        print(\"No highlight reel generated due to no detected events.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:38:08.922560Z","iopub.execute_input":"2025-04-19T03:38:08.922967Z","iopub.status.idle":"2025-04-19T03:38:08.929410Z","shell.execute_reply.started":"2025-04-19T03:38:08.922938Z","shell.execute_reply":"2025-04-19T03:38:08.928616Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class_names = ['Corner', 'Direct free-kick', 'Foul', 'Goal', 'Indirect free-kick', \n               'Kick-off', 'Offside', 'Shots off target', 'Shots on target', \n               'Substitution', 'Throw-in', 'Yellow card']\n\nweights_path = \"/kaggle/input/movinet-model-latest/keras/default/1/movinet_classifier_weights_epoch_10.weights.h5\"\nvideo_path = \"/kaggle/input/test-match-dataset/2_720p.mkv\"\n# video_path = \"/kaggle/input/test-match-dataset/1_720p.mkv\"\n\ntest_model(weights_path, video_path, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:38:10.651540Z","iopub.execute_input":"2025-04-19T03:38:10.651828Z","iopub.status.idle":"2025-04-19T03:41:47.695774Z","shell.execute_reply.started":"2025-04-19T03:38:10.651806Z","shell.execute_reply":"2025-04-19T03:41:47.694743Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745033891.865591     109 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Attempting to open video: /kaggle/input/test-match-dataset/2_720p.mkv\nPredicting events from preprocessed data with shape: (16, 224, 224, 3)\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745033923.875854     170 service.cc:152] XLA service 0x7f0bd4002450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745033923.875908     170 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1745033923.898941     170 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1745033924.488524     170 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Raw predictions: [[ 0.31843692 -1.0027473  -1.9367456  -1.8451654  -0.67007846  1.1106658\n  -3.4565277  -2.8935723  -3.9636736  -4.601125   -0.52038383 -1.0191002 ]]\nDetected events:\nEvent: Kick-off, Timestamp: 0.00s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 10.96s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 21.92s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 32.88s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 43.84s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 54.80s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 65.76s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 76.72s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 87.68s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 98.64s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 109.60s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 120.56s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 131.52s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 142.48s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 153.44s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 164.40s, Confidence: 1.1107\nEvent: Kick-off, Timestamp: 175.36s, Confidence: 1.1107\nVideo duration: 2810.0 seconds\nCreating highlight reel with 17 events: [(0.0, 'Kick-off', 1.1106658), (10.96, 'Kick-off', 1.1106658), (21.92, 'Kick-off', 1.1106658), (32.88, 'Kick-off', 1.1106658), (43.84, 'Kick-off', 1.1106658), (54.8, 'Kick-off', 1.1106658), (65.76, 'Kick-off', 1.1106658), (76.72, 'Kick-off', 1.1106658), (87.68, 'Kick-off', 1.1106658), (98.64, 'Kick-off', 1.1106658), (109.6, 'Kick-off', 1.1106658), (120.56, 'Kick-off', 1.1106658), (131.52, 'Kick-off', 1.1106658), (142.48, 'Kick-off', 1.1106658), (153.44, 'Kick-off', 1.1106658), (164.4, 'Kick-off', 1.1106658), (175.36, 'Kick-off', 1.1106658)]\nAdded clip from 0.00s to 5.00s, duration 5.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 5.96s to 15.96s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 16.92s to 26.92s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 27.88s to 37.88s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 38.84s to 48.84s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 49.80s to 59.80s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 60.76s to 70.76s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 71.72s to 81.72s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 82.68s to 92.68s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 93.64s to 103.64s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 104.60s to 114.60s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 115.56s to 125.56s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 126.52s to 136.52s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 137.48s to 147.48s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 148.44s to 158.44s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 159.40s to 169.40s, duration 10.00s for events [('Kick-off', 1.1106658)]\nAdded clip from 170.36s to 180.36s, duration 10.00s for events [('Kick-off', 1.1106658)]\nMoviepy - Building video /kaggle/working/highlight_reel_2.mp4.\nMoviePy - Writing audio in highlight_reel_2TEMP_MPY_wvf_snd.mp3\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video /kaggle/working/highlight_reel_2.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready /kaggle/working/highlight_reel_2.mp4\nHighlight reel generated: /kaggle/working/highlight_reel_2.mp4. Download 'output.zip' from the Output tab.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'official'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mofficial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmovinet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m movinet\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mofficial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmovinet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m movinet_model\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mofficial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m video_classification \u001b[38;5;28;01mas\u001b[39;00m base_cfg\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'official'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "from official.vision.configs import video_classification as base_cfg\n",
    "from official.vision.serving import export_saved_model_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_FRAMES = 30\n",
    "\n",
    "def load_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    while len(frames) < NUM_FRAMES:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < NUM_FRAMES:\n",
    "        frames += [np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)] * (NUM_FRAMES - len(frames))\n",
    "    \n",
    "    return np.array(frames[:NUM_FRAMES], dtype=np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    for label in class_names:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for file in os.listdir(label_dir):\n",
    "            if file.endswith('.mp4') or file.endswith('.avi'):\n",
    "                video_path = os.path.join(label_dir, file)\n",
    "                video = load_video(video_path)\n",
    "                videos.append(video)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return np.array(videos), np.array(labels), class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos, train_labels, class_names = load_dataset('../Dataset/split_data/train')\n",
    "test_videos, test_labels, _ = load_dataset('../Dataset/split_data/test')\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_videos, train_labels)).shuffle(100).batch(4).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_videos, test_labels)).batch(4).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = movinet.Movinet(model_id='a3', causal=False)\n",
    "model_cfg = backbone.default_config().clone()\n",
    "model_cfg.backbone.output_states = True\n",
    "\n",
    "base = movinet_model.MovinetClassifier(model_cfg, backbone=backbone)\n",
    "inputs = tf.keras.Input(shape=(NUM_FRAMES, IMG_SIZE, IMG_SIZE, 3))\n",
    "features, _ = base.backbone(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv3D(512, (3, 3, 3), padding='same', activation='relu')(features)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv3D(256, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "output = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=3, callbacks=[lr_callback])\n",
    "\n",
    "model.save(\"movinet_football_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
